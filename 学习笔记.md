# Python基础知识

## **Iterable和Iterator迭代器**

![img](file:///C:\Users\86180\AppData\Local\Temp\ksohtml14348\wps1.jpg) 

 

***\*问："任何类实现 __iter__() 即自动成为 Iterable 的实例（无需显式继承）"这一点似乎和Java显著不同，Java要求必须继承该接口才能实现该接口的函数\****

答：Python 采用 "鸭子哲学"："如果它走起来像鸭子，叫起来像鸭子，那它就是鸭子"

换言之，Python 采用 协议驱动 的接口实现。类只需实现特定方法（如 __iter__()），就被视为实现了对应接口，而不需要显式声明继承关系。这一点与Java显著不同。



## Python常见函数

### np.arange和range

| 对比点           | `np.arange`                                                  | `range`（Python 内置）                              |
| ---------------- | ------------------------------------------------------------ | --------------------------------------------------- |
| 所在模块         | `numpy`                                                      | 内置                                                |
| 返回类型         | `numpy.ndarray`（N 维数组）                                  | `range` 对象（惰性序列，可迭代）                    |
| 支持数据类型     | **整数 + 浮点数**，可指定 `dtype`                            | 仅整数                                              |
| 是否真正存储元素 | 是（连续内存），可随机索引、矢量化运算                       | 否（惰性/按需生成），需迭代取值                     |
| 常见用途         | 数值计算、构造坐标轴、矩阵索引                               | 循环计数、生成整数序列                              |
| 浮点步长风险     | 可能因二进制误差导致终点包含/排除不一致，官方推荐浮点用 `np.linspace` | 不支持浮点                                          |
| 示例             | `np.arange(0, 1, 0.2, dtype=np.float32)` → `array([0. , 0.2, 0.4, 0.6, 0.8])` | `range(0, 5, 2)` → `range(0, 5, 2)`（遍历得 0,2,4） |



## **Python基本数据结构**

### **1. 列表 (List)**

列表是 Python 中最常用的可变序列类型，可以存储任意类型的元素。

特点：

- 有序集合
- 可变（可以修改）
- 允许重复元素
- 可以包含不同类型的元素

```python
# 创建列表
my_list = [1, 2, 3, 'a', 'b', True]

# 访问元素
print(my_list[0])  # 输出: 1
print(my_list[-1])  # 输出: True (负索引表示从末尾开始)

# 切片操作
print(my_list[1:4])  # 输出: [2, 3, 'a']

# 修改元素
my_list[0] = 100

# 添加元素
my_list.append('new')  # 末尾添加
my_list.insert(2, 'inserted')  # 指定位置插入

# 删除元素
del my_list[0]  # 删除指定位置元素
my_list.remove('a')  # 删除第一个匹配的元素
popped = my_list.pop()  # 删除并返回最后一个元素

# 其他常用方法
length = len(my_list)  # 获取长度
if 'b' in my_list:  # 检查元素是否存在
    print("Found")

# 列表推导式
squares = [x**2 for x in range(10)]
```



### 2. 元组 (Tuple)

元组是不可变的序列类型，通常用于存储不应更改的数据集合。

特点：

- 有序集合
- 不可变（创建后不能修改）
- 通常比列表更快
- 可以作为字典的键（因为不可变）

```python
# 创建元组
my_tuple = (1, 2, 3, 'a', 'b')
single_element_tuple = (42,)  # 注意逗号，单个元素的元组必须加逗号

# 访问元素
print(my_tuple[0])  # 输出: 1

# 解包
a, b, c, d, e = my_tuple

# 不可变性示例
try:
    my_tuple[0] = 100  # 会抛出 TypeError
except TypeError:
    print("元组不可修改")

# 元组方法
index = my_tuple.index('a')  # 返回第一个匹配元素的索引
count = my_tuple.count(2)  # 计算元素出现次数
```

### 3. 数组

Python原生数组：array.array，原生array中所有元素都是相同类型的数字，内存结构紧凑，相对节约内存。

```python
import array

# 指定 typecode + 可迭代对象
a = array.array('i', [1, 2, 3])        
b = array.array('d', (0.1, 0.2, 0.3))  

# 空数组后续填充
c = array.array('f')                   

# 2.2 增删改查
a.append(5)            # 末尾添加
a.extend([6, 7])       # 批量添加，可迭代对象皆可
a.insert(0, 0)         # 指定位置插入
a.remove(3)            # 删除“值”为 3 的第一个元素
last = a.pop()         # 弹出并返回最后一个元素
idx = a.index(4)       # 返回值 4 的索引
cnt = a.count(2)       # 统计值 2 出现次数
a[1] = 99              # 直接修改
slice_part = a[1:4]    # 切片返回一个新的 array
```

| 代码  | 含义         | 字节宽度（依平台） |
| ----- | ------------ | ------------------ |
| `'b'` | 有符号 char  | 1                  |
| `'B'` | 无符号 char  | 1                  |
| `'h'` | 有符号 short | 2                  |
| `'i'` | 有符号 int   | 2 或 4             |
| `'l'` | 有符号 long  | 4                  |
| `'f'` | float        | 4                  |
| `'d'` | double       | 8                  |

科学计算的主力：numpy.ndarray

```python
import numpy as np

a = np.array([1, 2, 3], dtype=np.float32)
b = np.arange(12).reshape(3, 4)  # 3x4矩阵
c = a * 2                        # 向量化逐元素乘
d = b[:, 1:3]                    # 切片得到视图（不拷贝）
mean_col = b.mean(axis=0)

# 广播机制
a = np.random.rand(2, 3)
b = np.random.rand(2)       # 形状 (2,)
a + b                       # 如果这时a+b会导致ValueError，此时如果b.reshape(2,1)就能解决问题
							# 原理：广播从最后一维开始逐轴对齐，要求“两个轴长度相等 或 其中一个为 1”，在向前逐轴对齐的过程中，缺失的高维轴视为长度 1。reshape之后最后一维虽然仍不对齐，但为1，由NumPy虚拟拓展

```



# 哪些指标在不平衡数据集上准确有效？

传统的accuracy在极度不平衡的数据上容易被扭曲，不能真实的反映出模型的学习能力/泛化能力

## F1分数的不同变种

### F1分数：

传统F1分数是precision和recall的调和平均数

![image-20250715090604797](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250715090604797.png)

### 宏观F1分数（Macro F1）：

学习任务中每一类的传统F1分数的简单平均。当你想突出少数类对F1的影响时，也可以用于不平衡数据集的指标评价。

### 微观F1分数（Micro F1）：

适用于不平衡数据集，特别是你更关心整体的预测准确性，而非少数类。

其公式和F1保持一致，不同的是Micro-F1使用Micro-Precision和Micro-Recall

![image-20250715091716195](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250715091716195.png)

![image-20250715091734956](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250715091734956.png)

对于单标签的分类任务来说，微观F1分数恒等于微观精确率（Micro-Precision）、微观召回率（Micro-Recall）以及准确率（Accuracy）。

### 加权F1分数（Weighted F1）：

适用于不平衡数据集
$$
\text{Weighted F1} = \sum_{c=1}^{C} (\text{F1}_c \times \text{Support}_c / \text{Total Support})
$$
就是在F1分数前加了个权重，这个权重是由该类的数量比总数量来计算的。



## 准确率Accuracy：

### 代价敏感准确率：

代价敏感学习的核心思想是：**不同类型的错误，其代价（或后果的严重程度）是不同的。**

它不是一个有固定公式的独立评估指标，而是一种**框架**或**思想**。这个思想会直接影响模型的训练过程和最终的评估方式。其目标是最小化**总代价 (Total Cost)**。

![image-20250715101048698](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250715101048698.png)

![image-20250715101123252](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250715101123252.png)

### 平衡准确率（Balanced Accuracy）：

$$
 \text{Balanced Accuracy} = \frac{\text{Sensitivity} + \text{Specificity}}{2} = \frac{1}{2} \left( \frac{TP}{TP + FN} + \frac{TN}{TN + FP} \right) 
$$

**敏感度 (Sensitivity)**就是召回率 (Recall)，也叫真正例率TPR；**特异度 (Specificity)**也叫真负例率 (True Negative Rate, TNR)。它衡量**负类**被正确预测的比例，也可以理解为负例的召回率。

解决因数据不均衡导致的高准确率假象。例如，99%的样本是负类，模型只要把所有样本都预测成负类，准确率就能达到99%，但这毫无意义。平衡准确率会因为正类的召回率为0而变得很低（(0 + 1) / 2 = 0.5），从而揭示模型的问题。

但平衡准确率只看召回率不看precision，适用于漏诊代价特别高（看中召回率）的场景，比如癌症病人筛查。如果误诊（FP）和漏诊（FN）的代价相当则不适用。



# FocalLoss原理解析和代码实现

## 原理解析：

![image-20250717164502977](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250717164502977.png)

FocalLoss的改进：

![image-20250717165553279](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250717165553279.png)

## 代码实现：

```python
# 自定义 Focal Loss 函数（多分类）
def focal_loss_lgb(preds, train_data, alpha=(1.0, 2.5, 2.5), gamma=2.0):
    # train_data是lgb.DataSet类型,preds是ndarray,尺寸(4149,3),y_true也是ndarray,尺寸(4149,)
    
    """多分类 Focal Loss, 返回 grad、hess(均为 2-D)"""
    y_true = train_data.get_label().astype(int)
    n_samples = y_true.size

    alpha = np.asarray(alpha)

    probs = softmax(preds, axis=1)
    pt    = probs[np.arange(n_samples), y_true]              # 取出正确类概率
    focal = (alpha[y_true] * (1.0 - pt) ** gamma)[:, None]   # 计算聚焦因子focal

    grad = probs.copy()
    grad[np.arange(n_samples), y_true] -= 1
    grad *= focal                                           # 计算简化的一阶导数

    hess = probs * (1.0 - probs)
    hess *= focal											# 计算简化的二阶导数

    return grad, hess										# 返回一阶二阶导数给lightgbm
```



# 集成学习

集成学习可以被分为三个主要研究领域：

\- **模型融合**

  模型融合在最初的时候被称为“分类器结合”，这个领域主要关注强评估器，试图设计出强大的规则来融合强分类器的结果、以获取更好的融合结果。这个领域的手段主要包括了投票法Voting、堆叠法Stacking、混合法Blending等，且被融合的模型需要是强分类器。**模型融合技巧是机器学习/深度学习竞赛中最为可靠的提分手段之一，常言道：当你做了一切尝试都无效，试试模型融合。**

\- **弱分类器集成**

  弱分类器集成主要专注于对传统机器学习算法的集成，这个领域覆盖了大部分我们熟悉的集成算法和集成手段，如装袋法bagging，提升法boosting。这个领域试图设计强大的集成算法、来将多个弱学习器提升成为强学习器。

\- **混合专家模型**（mixture of experts）

  混合专家模型常常出现在深度学习（神经网络）的领域。在其他集成领域当中，不同的学习器是针对同一任务、甚至在同一数据上进行训练，但在混合专家模型中，我们将一个复杂的任务拆解成几个相对简单且更小的子任务，然后针对不同的子任务训练个体学习器（专家），然后再结合这些个体学习器的结果得出最终的输出。

**三种常见的决策树：**

![image-20250724153101615](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724153101615.png)

ID3倾向于选择那些**取值种类多**的特征。比如，如果用“学号”作为特征，每个学生一个学号，信息增益会非常大，但这样划分毫无泛化能力；C4.5是在ID3基础上改进的，用信息增益**除以**一个“固有值”（Intrinsic Value），这个固有值会惩罚那些取值种类多的特征，修正了这一问题，同时可以兼容连续值（但还是只能做分类）。

ID3基本没人用；C4.5可解释性更好，只适用于小数据集；CART是工业界标配，可用于集成学习，适合在大规模数据上快速运算，可解释性比C4.5稍弱。

## 弱分类器集成

### Bagging算法

1.Bootstrap采样：从原始训练集随机采样（有放回），生成若干个大小等于原始训练集的子集。每个子集可能包含重复的数据点，也可能缺失部分原始数据点。（这一步会产生袋外数据）

2.独立训练多个基模型：对每个子集训练一个基模型（如决策树、线性回归模型等），独立很重要，这些基模型越独立，Bagging对方差的抑制效果就越强。

3.聚合预测：对于分类任务，使用多数投票决定最终分类结果。对于回归任务，使用平均值作为最终预测结果。

**Bagging的缺点**

模型不可解释性：

1.由于 Bagging 聚合了多个模型的结果，最终的预测过程不易解释。

2.对基模型的选择依赖较高：Bagging通常对高方差、低偏差的基模型（如决策树）效果较好，但对高偏差的模型（如线性回归）效果有限。

3.计算资源消耗较大：需要训练多个基模型，计算和存储成本较高。



**偏差（Bias）** 和 **方差（Variance）** 是机器学习中两种衡量模型误差的关键指标，它们分别描述了模型的不同表现方面。它们共同影响模型的泛化能力，理解它们的区别对构建有效的模型至关重要。

偏差（Bias）

偏差是指模型预测值与真实值之间的差距，反映了模型的系统性误差。具体来说，偏差衡量的是模型对数据的拟合程度，偏差过大说明模型无法正确捕捉到数据的规律。

高偏差通常意味着模型过于简单，无法捕捉数据的复杂性，可能导致欠拟合（underfitting）。例如，使用线性回归去拟合一个复杂的非线性问题时，偏差会很高。

低偏差意味着模型能够较好地拟合数据。

方差（Variance）

方差是指模型在不同训练集上预测结果的变化程度，方差衡量的是模型有没有找到普适性的规律，方差过大说明模型过度关注训练数据的细节和噪声，可能导致过拟合（overfitting）。

高方差通常意味着模型过于复杂，拟合了训练数据中的噪声和细节，可能导致对新数据的泛化能力差。

低方差意味着模型对数据变化不太敏感，可能过于简化，导致无法捕捉到数据中的重要规律。



常见的bagging算法：随机森林和极端随机树（ExtraTrees）

#### 随机森林

**MSE（默认 `squared_error`）**：适合目标变量接近正态或误差对称、对大误差要严厉惩罚的场景。计算快，适合大数据量场景。

**MAE（`absolute_error`）**：MAE误差主要取决于中位数，子节点相比父节点中位数变化越大，减少的误差就越多，分裂越成功，因此会倾向把样本分到让**中位数变化最大**的分支。对异常值惩罚更小。但计算需反复排序，训练更慢。

随机森林参数重要性：

![image-20250723111959948](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250723111959948.png)



bagging思想—>RF各种参数—>如何精细调参（学习曲线和查看树结构）—>增量学习示例—>六大热点面试问题



### Boosting算法

![image-20250723210810852](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250723210810852.png)

#### AdaBoost

作为开山算法，AdaBoost的构筑过程非常简单：**首先，在全样本上建立一棵决策树，根据该决策树预测的结果和损失函数值，增加被预测错误的样本在数据集中的样本权重，并让加权后的数据集被用于训练下一棵决策树**。这个过程相当于有意地加重“难以被分类正确的样本”的权重，同时降低“容易被分类正确的样本”的权重，而将后续要建立的弱评估器的注意力引导到难以被分类正确的样本上。当全部弱评估器都被建立后，集成算法的输出H(x)等于所有弱评估器输出值的加权平均，加权所用的权重也是在建树过程中被自适应地计算出来的。

注意：以下内容是Boosting算法一般规则，并不局限于Adaboost，着重记忆最后两句。

![image-20250723213359947](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250723213359947.png)

##### 参数algorithm

​	参数`algorithm`是针对**分类器**设置的参数，有"SAMME"与"SAMME.R"两个选项，两者在数学原理上的区别不大，只不过SAMME是基于算法输出的具体分类结果（例如-1，1，2）进行计算，而SAMME.R则基于输出的概率值进行计算。但SAMME.R往往能够得到更好的结果，因此sklearn中的默认值是SAMME.R。

​	SAMME算法采用指数损失

​	二分类指数损失：
$$
L(H(x), y) = e^{-y H^*(x)}
$$
​	其中：
$$
H^*(x) =
\begin{cases}
1 & \text{if } H(x) > 0.5 \\
-1 & \text{if } H(x) < 0.5
\end{cases}
$$

$$
当算法预测正确时，yH^*(x)的符号为正,在函数 e^{-x} 上损失很小。\\
当算法预测错误时，yH^*(x) 的符号为负，在函数 e^{-x} 上损失较大。
$$

​	多分类指数损失：
$$
\begin{aligned}
L(H(x),y) &=exp \left( -\frac{1}{K}\boldsymbol{y^* · H^*(x)} \right) \\ 
& = exp \left( -\frac{1}{K}(y^{*1}H^{*1}(x)+y^{*2}H^{*2}(x) \ + \  ... + y^{*k}H^{*k}(x)) \right)
\end{aligned}
$$
​	对多分类指数损失，我们规定：
$$
H^*(x)=
\begin{cases}
1& if \ k = argmaxH(x) \\
-\frac{1}{K-1}& if\ k  \neq  argmaxH(x)
\end{cases}
\\
\\
y^*=
\begin{cases}
1& if \ k=y_i \\
-\frac{1}{K-1}& if\  k\neq y_i 
\end{cases}
$$
​	举例：

![image-20250724111037702](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724111037702.png)

K=2时多分类指数损失和二分类指数损失等价（尽管形式不完全相同）



SAMMR.R采取的损失函数：

![image-20250724112239652](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724112239652.png)

在 **SAMME.R** 中，弱学习器输出各类的连续得分；算法把这些得分做 **softmax** 变成概率，然后最小化 **多分类交叉熵损失**。这就是为什么 **SAMME.R**强制要求学习器输出分数而非类别。



##### 参数loss

参数loss是针对回归任务的，只包含一个选项：AdaBoost.R2，可以选择三种损失函数：

![image-20250724132645328](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724132645328.png)



##### 整体流程

$$
这里以AdaBoost.R2的流程为例 \\
假设现有数据集N，含有样本M个，任意样本编号为i，同时，弱评估器为决策树f，总共学习T轮\\
$$

![image-20250724141724133](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724141724133.png)

![image-20250724141852623](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724141852623.png)

![image-20250724142410325](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724142410325.png)

![image-20250724143207935](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724143207935.png)



#### GBDT

GBDT中所有的弱评估器都是回归树，因此在实际调用梯度提升树完成分类任务时，需要softmax函数或sigmoid函数对回归树输出的结果进行处理。

##### 8种损失函数

损失函数由loss参数控制

###### **分类器的loss**

‘deviance’(默认值) 、'exponential'，deviance代表交叉熵损失，exponential代表指数损失

![image-20250724171350392](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724171350392.png)

一般GBDT默认使用交叉熵损失。

######  **回归器中的loss**

"squared_error"（默认值）, "absolute_error", "huber", "quantile"

![image-20250724172402535](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724172402535.png)

![image-20250724172653852](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724172653852.png)



###### 选择不同损失函数

工业数据大部分都极度偏态、具有长尾，因此GBDT必须考虑**离群值**带来的影响。数据中的离群值会极大程度地影响模型的构建，当离群值在标签当中，而我们是依赖于减小损失函数来逐渐构建算法时，这种影响会前所未有地大。**因此Boosting是天生更容易被离群值影响的模型、也更擅长学习离群值的模型。**

![image-20250724173616336](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250724173616336.png)

一点思考：

![image-20250725153615231](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250725153615231.png)

![image-20250725153630036](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250725153630036.png)

##### 梯度提升树如何对抗过拟合

随机森林中任意控制过拟合的参数基本都处于“关闭状态”，例如`max_depth`的默认值为None，表示不限深度，`min_samples_splits`的默认值为2，等同于不限制分枝，因此随机森林中长出的树都是剪枝前的树，也因此当随机森林算法处于过拟合状态时，我们可以对弱评估器进行剪枝。然而这种情况并不适用于Boosting算法。

AdaBoost中使用的弱分类器都是最大深度为1的树桩，因此基于AdaBoost改进的其他Boosting算法也有该限制，即默认弱评估器的最大深度一般是一个较小的数字。**对GBDT来说，无论是分类器还是回归器，默认的弱评估器最大深度都为3**，因此GBDT默认就对弱评估器有强力的剪枝机制。

当随机森林处于过拟合状态时，还可通过降低弱评估器复杂度的手段控制过拟合，但GBDT等Boosting算法处于过拟合状态时，便只能从数据上下手控制过拟合了（例如，使用参数`max_features`，在GBDT中其默认值为None），毕竟当`max_depth`已经非常小时，其他精剪枝的参数如`min_impurity_decrease`一般发挥不了太大的作用。

也因此，通常认为Boosting算法比Bagging算法更不容易过拟合，一般在相似的数据上，Boosting算法表现出的过拟合程度会较轻。



##### 弗里德曼均方误差

![image-20250725155553469](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250725155553469.png)

##### GBDT的缺陷

GBDT没有class_weights参数，不能调整类别权重（但是有sample_weight，可以调节样本权重）

Boosting算法中的树是一颗一颗建立的，因此很难实现并行。虽然更先进的Boosting算法已经可以实现分支并行，但GBDT没有n_jobs参数，因此不能并行，运算速度是其显著缺点。



##### GBDT调参空间

![image-20250725161042708](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250725161042708.png)

然而你可能注意到，在随机森林中非常关键的`max_depth`在GBDT中没有什么地位，取而代之的是Boosting中特有的迭代参数学习率`learning_rate`。在随机森林中，我们总是在意模型复杂度(`max_depth`)与模型整体学习能力(`n_estimators`)的平衡，单一弱评估器的复杂度越大，单一弱评估器对模型的整体贡献就越大，因此需要的树数量就越少。在Boosting算法当中，单一弱评估器对整体算法的贡献由学习率参数`learning_rate`控制，代替了弱评估器复杂度的地位，因此Boosting算法中我们寻找的是`learning_rate`与`n_estimators`的平衡。同时，Boosting算法天生就假设单一弱评估器的能力很弱，参数`max_depth`的默认值也往往较小（在GBDT中`max_depth`的默认值是3，AdaBoost的默认值是1），因此我们无法靠降低`max_depth`的值来降低模型复杂度和控制过拟合。

在讲解随机森林时我们提到过，精剪枝工具的效用有限，剪枝一般还是大刀阔斧的粗剪枝更有效。在GBDT中，通过削减模型复杂度来控制过拟合的思路无法走通。如果无法对弱评估器进行剪枝（因为剪无可剪），最好的控制过拟合的方法就是增加数据随机性/多样性，因此`max_features`和`subsample`就成为Boosting算法中控制过拟合的核心武器。当然降低learning_rate也是可以控制过拟合的。

比起Bagging，Boosting更加擅长处理小样本高维度的数据，因为Bagging数据很容易在小样本数据集上过拟合。（Bagging每次采样都只能覆盖很小的一部分特征空间；原始样本数量已经少，自助采样后会有袋外数据，数据代表性更差；高维数据相对难找到准确切分点；再配合不限制树深，因此极易学习噪声形成过拟合。Boosting树深浅，更不易过拟合。）

需要注意的是，虽然`max_depth`在控制过拟合上的贡献不大，但是我们在调参时依然需要保留这个参数。当我们使用参数`max_features`与`subsample`构建随机性、并加大每一棵树之间的差异后，模型的学习能力可能受到影响，因此我们可能需要提升单一弱评估器的复杂度。**因此在GBDT当中，`max_depth`的调参方向是放大/加深，以探究模型是否需要更高的单一评估器复杂度。相对的在随机森林当中，`max_depth`的调参方向是缩小/剪枝，用以缓解过拟合**。

那在调参的时候，我们应该选择哪些参数呢？与随机森林一样，我们首先会考虑所有影响力巨大的参数（5星参数），当算力足够/优化算法运行较快的时候，我们可以考虑将大部分时候具有影响力的参数（4星）也都加入参数空间，如果样本量较小，我们可能不选择`subsample`。除此之外，我们还需要部分影响弱评估器复杂度的参数，例如`max_depth`。



##### GBDT数学原理

![image-20250725165829536](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250725165829536.png)

AdaBoost拟合的是真实值，不需要初始迭代起点；GBDT拟合的是伪残差，而本轮伪残差的计算依赖上一轮的预测结果，因此必然需要一个第0轮的预测结果（初始迭代起点）

从GBDT开始，集成学习算法可以控制本轮训练集的抽样比例subsample（名字会有变化）

![image-20250725170137970](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250725170137970.png)



#### XGBoost

![image-20250727104326965](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250727104326965.png)

![image-20250727110259292](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250727110259292.png)

![image-20250727111133820](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250727111133820.png)

##### 基本流程



##### 目标函数

**XGBoost向着令目标函数最小化的方向运行**。

需要注意的是，损失函数可以针对单个样本进行计算，也可以针对整个算法进行计算，**但在XGBoost的定义中，目标函数是针对每一棵树的，而不是针对一个样本或整个算法**。对任意树$f_k$来说，目标函数有两个组成部分，一部分是任意可微的损失函数，它控制模型的**经验风险**。从数值上来说，它等于现在树上所有样本上损失函数之和，其中单一样本的损失为$l(y_i,\hat{y_i})$。另一部分是控制模型复杂度的$\Omega(f_k)$，它控制当前树的**结构风险**。
$$
Obj_k = \sum_{i=1}^Ml(y_i,\hat{y_i}) + \Omega(f_k)
$$
其中$M$表示现在这棵树上一共使用了M个样本，$l$表示单一样本的损失函数。当模型迭代完毕之后，最后一棵树上的目标函数就是整个XGBoost算法的目标函数。

\- **经验风险**：模型对数据学习越深入，损失越小（经验风险越小），模型对数据学习得越浅显，损失越大（经验风险越大）。

\- **结构风险**：树结构越复杂、模型复杂度越高，过拟合风险越大（结构风险越大）。树模型结构越简单、模型复杂度越低、过拟合风险越小（结构风险越小）。

在具体的公式当中，结构风险$\Omega(f_k)$又由两部分组成，一部分是控制树结构的$\gamma T$，另一部分则是正则项：
$$
\Omega(f_k) = \boldsymbol{\color{red}\gamma} T + \frac{1}{2}\boldsymbol{\color{red}\lambda}\sum_{j=1}^Tw_j^2 + \boldsymbol{\color{red}\alpha}\sum_{j=1}^Tw_j
$$
其中$\gamma$，$\lambda$与$\alpha$都是可以自由设置的系数，而$T$表示当前第$k$棵树上的叶子总量，$w_j$则代表当前树上第$j$片叶子的叶子权重（leaf weights）。**叶子权重是XGBoost数学体系中非常关键的一个因子，它实际上就是当前叶子$j$的预测值**，这一指标与数据的标签量纲有较大的关系，因此当标签的绝对值较大、$w_j$值也会倾向于越大。因此正则项有两个：使用平方的L2正则项与使用绝对值的L1正则项。

\- 参数`gamma`：乘在一棵树的叶子总量$T$之前，依照叶子总量对目标函数施加惩罚的系数，默认值为0，可填写任何[0, ∞]之间的数字。当叶子总量固定时，`gamma`越大，结构风险项越大；同时，当`gamma`不变时，叶子总量越多、模型复杂度越大，结构风险项也会越大。在以上两种情况下，目标函数受到的惩罚都会越大，因此调大**`gamma`**可以控制过拟合。

\- 参数`alpha`与`lambda`：乘在正则项之前，依照叶子权重的大小对目标函数施加惩罚的系数，也就是正则项系数。`lambda`的默认值为1，`alpha`的默认值为0，因此xgboost默认使用L2正则化。通常来说，我们不会同时使用两个正则化。$\sum_{j=1}^Tw_j$是当前树上所有叶子的输出值之和，因此当树上的叶子越多、模型复杂度越大时，对整体目标函数的惩罚就越重。

##### 三大评估器与DART树

- 参数`booster`：使用哪种弱评估器。

> 可以输入"gbtree"、"gblinear"或者"dart"。
>
> 输入"gbtree"表示使用遵循XGBoost规则的CART树，我们之前提到的XGBoost在GBDT上做出的改善基本都是针对这一类型的树。这一类型的树又被称为“XGBoost独有树”，XGBoost Unique Tree。
>
> 输入"dart"表示使用抛弃提升树，DART是Dropout Multiple Additive Regression Tree的简称。这种建树方式受深度学习中的Dropout技巧启发，在建树过程中会随机抛弃一些树的结果，可以更好地防止过拟合。在数据量巨大、过拟合容易产生时，DART树经常被使用，但由于会随机地抛弃到部分树，可能会伤害模型的学习能力，同时可能会需要更长的迭代时间。
>
> 输入"gblinear"则表示使用线性模型，当弱评估器类型是"gblinear"而损失函数是MSE时，表示使用xgboost方法来集成线性回归。当弱评估器类型是"gblinear"而损失函数是交叉熵损失时，则代表使用xgboost来集成逻辑回归。
>
> 每一种弱评估器都有自己的params列表，例如只有树模型才会有学习率等参数，只有DART树才会有抛弃率等参数。评估器必须与params中的参数相匹配，否则一定会报错。其中，由于DART树是从gbtree的基础上衍生而来，因此gbtree的所有参数DART树都可以使用。

使用DART树会用到的参数：

- 参数`rate_drop`：每一轮迭代时抛弃树的比例
> 设置为0.3，则表示有30%的树会被抛弃。只有当参数`booster`="dart"时能够使用，只能填写[0.0,1.0]之间的浮点数，默认值为0。
- 参数`one_drop`：每一轮迭代时至少有`one_drop`棵树会被抛弃
> 可以设置为任意正整数，例如`one_drop` = 10，则意味着每轮迭代中至少有10棵树会被抛弃。
>
> 当参数`one_drop`的值高于`rate_drop`中计算的结果时，则按照`one_drop`中的设置执行Dropout。例如，总共有30棵树，`rate_drop`设置为0.3，则需要抛弃9棵树。但`one_drop`中设置为10，则一定会抛弃10棵树。当`one_drop`的值低于`rate_drop`的计算结果时，则按`rate_drop`的计算结果执行Dropout。
- 参数`skip_drop`：每一轮迭代时可以不执行dropout的概率
> 即便参数`booster`='dart'，每轮迭代也有`skip_drop`的概率可以不执行Dropout，是所有设置的概率值中拥有最高权限的参数。该参数只能填写[0.0,1.0]之间的浮点数，默认值为0。当该参数为0时，则表示每一轮迭代都一定会抛弃树。如果该参数不为0，则有可能不执行Dropout，直接按照普通提升树的规则建立新的提升树。
>
> 需要注意的是，`skip_drop`的权限高于`one_drop`。即便`one_drop`中有所设置，例如每次迭代必须抛弃至少10棵树，但只要`skip_drop`不为0，每轮迭代则必须经过`skip_drop`的概率筛选。如果`skip_drop`说本次迭代不执行Dropout，则忽略`one_drop`中的设置。
- 参数`sample_type`：抛弃时所使用的抽样方法
> 填写字符串"uniform"：表示均匀不放回抽样。
> 填写字符串"weighted"：表示按照每棵树的权重进行有权重的不放回抽样。
> 注意，该不放回是指在一次迭代中不放回。**每一次迭代中的抛弃是相互独立的，因此每一次抛弃都是从所有树中进行抛弃**。上一轮迭代中被抛弃的树在下一轮迭代中可能被包括。
- 参数`normalize_type`：增加新树时，赋予新树的权重
> 当随机抛弃已经建好的树时，可能会让模型结果大幅度偏移，因此往往需要给与后续的树更大的权重，让新增的、后续的树在整体算法中变得更加重要。所以DART树在建立新树时，会有意地给与后续的树更大的权重。我们有两种选择：
> 填写字符串"tree"，表示新生成的树的权重等于所有被抛弃的树的权重的均值。
> 填写字符串"forest"，表示新生成的树的权重等于所有被抛弃的树的权重之和。
> 算法默认为"tree"，当我们的dropout比例较大，且我们相信希望给与后续树更大的权重时，会选择"forest"模式。



##### 弱评估器的分支

**假设现在目标函数使用L2正则化，控制叶子数量的参数**`gamma`**为0。现在存在一个叶子节点$j$，对该节点来说结构分数的公式为：**
$$
Score_j = \frac{(\sum_{i \in j}g_i)^2}{\sum_{i \in j}h_i + \lambda}
$$
其中，$g_i$是样本$i$在损失函数$L$上对预测标签求的一阶导数，$h_i$是样本$i$在损失函数$L$上对预测标签求的二阶导数，$i \in j$表示对叶子$j$上的所有样本进行计算，$\lambda$就是L2正则化的正则化系数。所以不难发现，结构分数实际上就是：
$$
Score_j = \frac{节点j上所有样本的一阶导数之和的平方}{节点j上所有样本的二阶导数之和 + \lambda}
$$
需要注意结构分数是针对节点计算的，我们以前学习的不纯度衡量指标如基尼系数、信息熵等也是如此。在此基础上，我们依赖于结构分数增益进行分枝，结构分数增益表现为：
$$
\begin{align}

Gain &= Score_L + Score_R - Score_P \\ \\

&= \frac{(\sum_{i \in L}g_i)^2}{\sum_{i \in L}h_i + \lambda} + \frac{(\sum_{i \in R}g_i)^2}{\sum_{i \in R}h_i + \lambda} - \frac{(\sum_{i \in P}g_i)^2}{\sum_{i \in P}h_i + \lambda}\\ \\

\end{align}
$$
这即是说，结构分数增益实际上就是：

$$Gain = 左节点的结构分数 + 右节点的结构分数 - 父节点的结构分数$$

**我们选择增益$Gain$最大的点进行分枝**。

你是否注意到，XGBoost中的分枝规则与经典CART树的分枝规则在细节上有所不同？CART树中所使用的信息增益是：

$$CART树中的信息增益 = 父节点的不纯度 - （左节点的不纯度 + 右节点的不纯度）$$

无论不纯度衡量指标是基尼系数还是信息熵，不纯度是越小越好。然而在XGBoost当中，增益的计算公式与CART树相反，但我们依然追求最大增益，所以这意味着**随着XGBoost树的建立，整体结构分数是逐渐上升的**。





#### LightGBM

​	Lightgbm提出的核心目的是为了解决GBDT算法在处理海量数据时效率低下的问题。LGBM最终能以极小的精度牺牲为代价，将GBDT的计算效率提升了20倍。LGBM在迭代过程上基本照搬XGB，但其在数据压缩技术和决策树训练方法上做了许多创新。

##### LightGBM的数据压缩策略

​	LightGBM建模过程总共会进行**两方面**的数据压缩：

​	首先是EFB算法进行特征数量的压缩。在全样本上连续变量分箱（连续变量离散化，就是简单的等宽分箱），然后将离散特征和离散后的连续变量进行离散特征捆绑（合并）降维。其中提到的特征捆绑降维，互斥特征捆绑（Exclusive Feature Bundling, EFB）算法也是由LGBM首次提出，能够很好的克服传统降维方法带来的信息大量损耗的问题；

​	其次是GOSS算法进行样本数量的压缩。LGBM在每次迭代（也就是每次训练一颗决策树模型）的时候，还会围绕训练数据集进行下采样，此时的下采样不是简单的随机抽样，而是一种名为基于梯度的单边采样（Gradient-based One-Side Sampling, GOSS）的方法，和EFB类似，这种方法能够大幅压缩数据，但同时又不会导致信息的大量损失。

​	不难发现，最终输入到每颗决策树进行训练的数据，实际上是经过大幅压缩后的数据，这也是LGBM计算高效的根本原因之一。

##### 特征互斥捆绑EFB

EFB收到了独热编码的启发。如图所示，独热编码是从左往右的，而EFB可以视为独热编码的逆向过程。

![image-20250718164639847](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250718164639847.png)

​	独热编码适用于表征离散特征，但lightgbm设计用于处理海量数据且所有特征全部离散化，应用独热编码只会进一步加剧维度灾难。

​	独热编码通常并不会让决策树集成模型表现更好，原因：（1）对树而言，“把 A 类单独当成 1、其他全 0” 和 “在原始标签上做 {A} vs 其他” 其实是同一件事：都能把 A 和非 A 分开。独热编码并未创造任何树无法自己生成的分裂方式；只是 **把一个本来可以一次完成的多路划分拆成了多次二分**。（2）独热编码会立刻让数据集变稀疏、高维。树模型很难在这样的特征空间中找到合适的分类点，会需要更多的树或更深的树去学习，易过拟合或训练更慢。

​	简单来说：EFB的目标是找到那些原始状态下就存在类似上图中x1和x2这种关系的特征，来将其合成为一个特征。x1和x2存在一种这样的关系——任何一条样本都不会同时在x1和x2上取值非0，因此被称作互斥特征，而互斥特征在合成的过程并不会有任何的信息损失，合成的过程又被称作特征捆绑。

​	离散特征通常不需要做EFB，因为EFB）只对**“高维、稀疏、互斥”**的特征有效，而离散特征通常不符合这三个条件：

| 原理/现象                                                    | 离散特征的特点                                               | 与 EFB 的冲突                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------------------- |
| **EFB 针对稀疏互斥**— 只有当两列在同一行几乎不会同时出现非零时，才值得打包在一个 bundle 里 | **离散列非稀疏**：每一行都必定填一个类别取值（哪怕用 0/1/2… 这样的整数标签），不会出现大量 0 | → 冲突率高，EFB 会直接放弃打包                |
| **EFB 的收益在于减少列数**— 典型场景是一大批 one‑hot 列互斥  | 离散列本身列数就不多（1 列/特征），不需要降维                | → 压缩“收益”几乎为 0                          |
| **LightGBM 对类别特征有原生支持**— 不需要先 one‑hot          | 把列标记 `categorical_feature` 即可，内部自动做最优划分      | → 再去 one‑hot + EFB 反而多此一举、还浪费内存 |

###### EFB算法基本原理

**冲突比例（非互斥比例）**：用于表征两个特征冲突（非互斥，或者说同时取非0值）的比例。LGBM提供了一个max_conflict_rate，低于该比例则认为不冲突（互斥）。

**图着色**：LGBM会将特征捆绑问题转化为一个图着色的问题(Graph Coloring Problem)。图着色问题一种经典的组合优化问题，其问题描述为：给定一个无向图，如何用尽量少的颜色对图中的每个顶点进行着色，使得相邻的顶点颜色不同。这里的“颜色”可以是任意一种符号或编号，只要保证相邻的顶点不同即可。在EFB计算过程中，会将不同特征视作图上的一个个点，若特征之间存在冲突，则用一条无向边进行连接，边的权重就是冲突比例，而如果两个特征互斥，则彼此没有边进行相连。而在将特征及其冲突情况用图进行展示后，即可进一步进行图着色——即在相邻的点颜色不同的前提条件下，用尽可能少的颜色（合并成尽可能少的特征）对图上的点进行着色，既然相互冲突的特征都有边进行相连，那么相同颜色的点其实就是互斥的特征，接下来我们仅需把相同颜色的特征进行合并即可。

###### 捆绑的过程：

在 EFB（Exclusive Feature Bundling，互斥特征捆绑）里，**真正“捆绑”的不是把两列数值简单相加**，而是把它们的 **“直方图桶（bin）编号”** 串接到同一条数轴上，用 **偏移量（offset）** 做区分。核心流程可以分成三步：

------

**1 先对单列特征做直方图离散化**

LightGBM 本来就是基于直方图的 GBDT 实现，每一列特征会被离散到 k 个桶（默认 ≤ 255）。此时，某条样本在这列上的值已经不是连续实数，而是 **bin index**（0 ~ k‑1）。

------

**2 给同一个 bundle 内的每个子特征分配「专属区间」**

假设要把 A、B 两列捆到一起，它们各自有

- A：k_A 个桶 → 编号 0 ~ k_A-1
- B：k_B 个桶 → 编号 0 ~ k_B-1

捆绑时：

![image-20250718191400258](C:\Users\86180\AppData\Roaming\Typora\typora-user-images\image-20250718191400258.png)

即 **累加前面特征的桶数当作偏移量**。同一个样本如果 A 非零，就把
$$
\text{bundle\_value}= \text{bin}(A) + O_A
$$
写进“捆好”的那一列；如果 A 为零而 B 非零，则写
$$
\text{bundle\_value}= \text{bin}(B) + O_B
$$
由于 A 和 B 被判定为“互斥”（同一行不会同时非零），**任何时刻 bundle 里只会出现一列的有效信息**，不会冲突。这样便完成了压缩。若允许小幅冲突（`max_conflict_rate` > 0），LightGBM 也只是把冲突行当成轻微近似，整体流程不变。

------

**3 训练与分裂：在偏移区间里做局部搜索**

捆绑后的一列拥有 k_A + k_B 个桶。LightGBM 在建树时遍历 split 点，本质就是把 **“低于阈值”** 的样本送左子树。

- 当阈值落在 [0, k_A) 内，本质是在 **A** 上做分裂；
- 当阈值落在 [k_A, k_A+k_B) 内，本质是在 **B** 上做分裂。

因为 offset 设计成不重叠，LightGBM 能精确还原“到底分了哪一列、哪一个 bin”，与单独训练效果等价。



##### 基于梯度的单边采样GOSS

​	在执行优化算法的过程中，每个样本都有一个对应的梯度计算结果，如果某条样本梯度绝对值较小，则说明这条样本已经被正确的分类或者预测结果和真实结果非常接近，在后续的参数更新过程中，这些梯度绝对值较小的样本对参数的改进贡献较小，因此每次迭代计算时再把这些小梯度的样本再算一遍梯度，会一定程度造成资源浪费。而反观那些梯度绝对值较大的样本，这些样本具有更高的误差，因此对模型的训练有更大的贡献。因此GOSS（Gradient-based One-Side Sampling）的思路是将全部样本按照梯度绝对值大小进行降序排序，然后抽取梯度绝对值最大的前a%的样本，然后把其他样本都视作小梯度样本，并从这些小梯度样本中随机抽取b%个样本，而这些大梯度样本和随机抽取的小梯度样本，就构成了接下来模型训练的数据集。而只针对小梯度样本（一边）进行抽样、保留（另一边）全部大梯度样本，也就是单边采样一词的由来。

​	注意几个要点：

​	1.GOSS计算过程是根据梯度的绝对值大小进行样本划分和抽样，并不是样本梯度的真实值；

​	2.GOSS中样本选取比例，也就是梯度绝对值最大的前a%和小样本中随机抽样的b%，实际上都是超参数，可以在建模过程中灵活调节。这里的a%可以换成更专业的超参数名称：top_rate，而小样本抽取的b%更专业的名称则是other_rate；     

​	3.我们知道样本梯度是基于预测结果计算而来的（具体来说是损失函数的一阶导数），而在第一棵树构建之前我们就需要进行GOSS采样，此时还没有模型预测结果，梯度计算依据的是LGBM的初始预测值，和其他集成学习类似，不同的损失函数计算初始值的方式不相同；

​	4.由于每次迭代都会更新模型参数，因此每次建树之前都会重新进行抽样，而除非人为控制迭代过程（例如使用一种非常特殊的Booster API，后面会详细介绍），否则一般来说top_rate和other_rate设置好了就不会再发生变化；     

​	5.关于top_rate和other_rate的数值设置，一般来说top_rate越大other_rate越小，则模型过拟合风险就越大，反之则模型学习能力会被限制，而如果这两个参数同时较大，则会增加模型训练复杂度，增加模型训练时间。关于这组参数，并没有一个普遍适用的取值，还是需要根据实际情况进行超参数优化。

​	6.尽管带入训练的数据是GOSS抽样后的数据，但在后续决策树生长的过程中，小梯度样本的梯度（和损失函数二阶导数）会再乘以一个大于1的膨胀系数，再和大梯度样本的梯度（和损失函数二阶导数）进行相加，构成一个数据集的梯度（和损失函数二阶导数），来指导后续的迭代进行。而之所以要让小梯度样本进一步膨胀再加入到样本数据梯度中，其实也是为了尽可能还原原始真实的数据集梯度。也即是说，GOSS抽样并不是想要改变数据集梯度，而是希望通过更小的计算量，来尽可能还原原始数据集完整梯度，以此来提升建模的精确度，其基本过程可以由下图进行表示：

<img src="https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/202303231809934.png" alt="5a9d29da9104eae4106ca796a7a493c" style="zoom:50%;" />膨胀系数计算公式：
$$
\frac{1-top\_rate}{other\_rate}
$$


##### LightGBM的决策树训练优化策略

​	其一是**直方图优化算法**，通过直方图的形式更加简洁的表示每次分裂前后数据节点的核心信息，并且父节点和子节点也可以通过直方图减法计算直接算得，从而加速数据集分裂的计算过程:

​	其二则是leaf wise tree growth的**叶子节点优先的决策树生长策略**，对于其他大多数决策树算法来说，树都是一次生长一层，也就是Level-wise tree growth（深度优先的生长策略）。叶子结点优先的生长策略会让树的计算过程变得更复杂，但会提高树的收敛速度。前者可以通过数据压缩策略来对冲。

###### 直方图优化算法

​	LGBM和XGB的直方图算法在直方图的表示形式上并没有任何区别，只是在直方图统计的值方面有区别：XGB是用直方图统计样本值的累加（并对特征进行排序），而LGBM是用直方图统计数据集的一阶导数和Hessian值的累加（并对特征进行排序）。也正因如此，LGBM可以利用直方图进行差分加速，而XGB不行。从这点而言，LGBM的直方图优化算法可以视作XGB直方图优化算法的优化版本。当然除此之外，LGBM还有很多并行计算的策略，进一步加速其计算过程。

​	LGBM的决策树生长流程对每个备选节点的分裂增益的计算过程略显繁琐，每次都需要计算子数据集的grad和及hess，并区分大梯度样本和小梯度样本，然后赋予不同的权重进行求和，这个大小梯度样本的检索过程在实际过程中是极耗费计算量的。

​	为了能够加速计算过程，LGBM提出了基于梯度和及hess和的直方图优化算法，该算法首先要求用直方图来表示各数据集的梯度和、hess和的累计值，然后从数学层面可以非常简单的证明，在**决策树分裂过程中梯度和、hess和整体累计值不变**，因此子节点的梯度和、hess和的累计值将和父节点相同，进而在决策树分裂过程中，我们只需要计算父节点和左子树的梯度和、hess和，就能通过相减的方式得到右子树的梯度和、hess和，也就是直方图优化算法中的差加速优化。



###### 决策树生长的增益计算公式

​	不同于CART树的基于基尼系数差的增益计算方法和C4.5的基于信息熵的信息增益，LGBM采用了一种非常特殊的、同时包含梯度和Hessian值得分裂增益计算方法，具体计算公式如下：
$$
Gain = \frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda} - \alpha \cdot (|w_L|+|w_R|)
$$
​	其中，G_L 和 G_R 分别左节点和右节点的梯度和，H_L 和 H_R 分别是左节点和右节点的Hessian和，  **λ** 是 reg_lambda 参数（L2正则化项），α 是 reg_alpha 参数（L1正则化项），w_L 和 w_R 分别是左节点和右节点的权重。并且，对于一个节点，权重计算公式如下：
$$
w=-\frac{G}{H+\lambda}
$$
​	而对于reg_alpha和reg_lambda，其实是模型的两个超参数，也被称作L1正则化参数和L2正则化参数，用于控制模型结构风险。根据分裂增益计算公式不难看出，在数据集梯度和Hessian固定不变的情况下，L1正则化参数和L2正则化参数取值越大，增益计算结果就越小，决策树就越倾向于不分裂。

###### Leaf Wise Tree Growth生长策略

​	CART树就是一种Leaf wise tree growth，而C3.0就是Level-wise tree growth，这里我们可以理解为LGBM就是采用了CART树类似的生长流程即可。相比层次优先的生长策略，叶节点优先的生长策略会耗费更多的计算量，增加过拟合风险（因此max_depth对于LGBM是一个重要参数），但同时也会有更高的预测精度。大多数集成学习算法为了提高计算效率，都采用的层次优先的生长策略（比如XGB），而LGBM经过了一系列数据压缩和其他优化方法，本来就拥有非常高的计算效率，因此在具体决策树建模的时候采用了一种更高精度叶节点优先的策略，来确保其在压缩后的数据上能够获得更高的预测精度。

